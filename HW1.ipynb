{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COSE 471 Data Science\n",
    "## Homework Week2-3\n",
    "\n",
    "- Week 2 : Data and Visual Attributes / Statistical Graphs\n",
    "- Week 3 : Data Munging\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "__ Ready to enjoy python for data mining __\n",
    "1.  install [python](https://www.python.org/)\n",
    "\n",
    "2. install libraries\n",
    "     - install [anaconda](https://www.continuum.io/downloads) for science, math, and data analysis.\n",
    "\n",
    "     - _or_ install libraries\n",
    "         - [numpy](http://docs.scipy.org/doc/numpy-dev/user/index.html), fot arrays\n",
    "         - [pandans](http://pandas.pydata.org/), for data frames\n",
    "         - [matplotlib](http://matplotlib.org/), for plotting\n",
    "         - [requests](http://docs.python-requests.org/en/latest/), for fetching web content\n",
    "         - [pattern](http://www.clips.ua.ac.be/pages/pattern) or [beautiful soup](http://www.crummy.com/software/BeautifulSoup/bs4/doc/), for parsing html and xml pages\n",
    "         - [fnmatch](https://docs.python.org/2/library/fnmatch.html) (optional), for Unix-style string matching\n",
    "         \n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check all libararies are installed\n",
    "import requests\n",
    "import re\n",
    "from pattern import web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect and Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to analysis data, first you would collect and clean data.\n",
    "\n",
    "> Choose whiche domain has the data\n",
    ">\n",
    "> Recognize web page architecture to collect each movie (entity)\n",
    ">\n",
    ">> Analysis HTML code hierarchy or structure\n",
    ">>\n",
    ">> Extract the useful or necessary data\n",
    ">>\n",
    ">>> Formatting, Cleaning, and Sampling data\n",
    ">>> \n",
    ">>> Scaling, Decomposition, Aggregation\n",
    "\n",
    "\n",
    "In this homwork, we will analysis movie review data in [IMDB](http://www.imdb.com/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "To collect movie data, we will implement the function fetching the detail page of movie review.\n",
    "\n",
    "Page URL is like below.\n",
    "\n",
    "| Movie Title | Detail page URL |\n",
    "|------------------------|----------------------------------|\n",
    "|The Dark Knight (2008)|http://www.imdb.com/title/tt0468569/|\n",
    "|Inception (2010)|http://www.imdb.com/title/tt1375666/|\n",
    "|Interstellar (2014) |http://www.imdb.com/title/tt0816692/|\n",
    "|Avengers: Age of Ultron (2015)|http://www.imdb.com/title/tt2395427/|\n",
    "| ..... | .....|\n",
    "\n",
    "As you can see, The detail pages of movie review have similar pattern. \n",
    "\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Fill in the code for the __get_movie_detaill_page(movie_id)__, that fetches HTML page about the movie of which id is __movie_id__ ( _tt0468569_ is the movie id of 'The Dark Knight' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Function\n",
    "get_movie_detaill_page\n",
    "\n",
    "Given a movie_id, return the HTML document.\n",
    "\n",
    "@Inputs\n",
    "__\n",
    "movie_id : str\n",
    "    The ID of the movie to be fetched\n",
    "\n",
    "@Returns\n",
    "___\n",
    "html : str\n",
    "    The HTML string for that movie_id\n",
    "    \n",
    "@Example\n",
    "___\n",
    ">>> get_movie_html('tt0468569')\n",
    "u'<html xmlns:og=\"http://ogp.me/ns#\" xmlns:fb=\"http://www.facebook.com/2008/fbml\">\n",
    "....\n",
    "\"\"\"\n",
    "\n",
    "def get_movie_detaill_page(movie_id):\n",
    "    # your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test\n",
    "\"\"\"\n",
    "Expected Result\n",
    "--> u'\\n\\n\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html\\nxmlns:og=\"http://ogp.me/ns#\"\\nxmlns:fb=\"http://www.facebook.co..........\n",
    "\"\"\"\n",
    "\n",
    "test_html = get_movie_detaill_page('tt0816692') #interstellar (2016)\n",
    "test_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "Until now, we have learned that we could collect a descriptive page of the movie by it's 'movie_id'.\n",
    "\n",
    "However, the HTML format contains a lot of additional data that are not essential nor integral for our purpose.\n",
    "\n",
    "Therefore, we need to conduct a method called 'first degree data cleaning', which means extracting the data we need\n",
    "from the HTML we have recently fetched.\n",
    "\n",
    "http://www.clips.ua.ac.be/pages/pattern-web\n",
    "> Above is the link to the description of HTML DOM parser\n",
    "(Equivalent to CSS selector query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def str2number(number_str):\n",
    "    if number_str is None:\n",
    "        return None\n",
    "    else:\n",
    "        number_str = re.sub(\"[^0-9]\", \"\", number_str)\n",
    "        return int(number_str)\n",
    "\n",
    "time_p = re.compile(\"(.*?)h (.*?)min\")\n",
    "def str2time(time_str):\n",
    "    m = time_p.match(time_str)\n",
    "    \n",
    "    if m:  # include hour\n",
    "        hour = int(m.group(1))\n",
    "        minute = int(m.group(2))\n",
    "        \n",
    "        time = (hour *60) + minute\n",
    "    else: # not include hour, only minute\n",
    "        time = str2number(time_str)\n",
    "        \n",
    "    return time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can observed that the results of the HTML parser are all consisted with a String data type.\n",
    "\n",
    "Now we need to cast the results into the data type we want using the two functions above.\n",
    "\n",
    "This process will convert the data into a more conformable form for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Function\n",
    "parsing_detail_page\n",
    "\n",
    "Given a HTML string, return the useful data.\n",
    "\n",
    "@Inputs\n",
    "---\n",
    "html: str\n",
    "    The HTML for the movie_id\n",
    "\n",
    "@Returns\n",
    "----\n",
    "object: dict (all value is str, not casting!)\n",
    "    {\n",
    "     'duration': [:int],\n",
    "     'genre': [:list]    ex. [u'Adventure', u'Drama', u'Sci-Fi'],\n",
    "     'rating': [:float],\n",
    "     'rating_count': [:int],\n",
    "     'review_count': [:int],\n",
    "     'title': [:str],\n",
    "     'year': [:int]\n",
    "     }\n",
    "\"\"\"\n",
    "\n",
    "def parsing_detail_page(html):\n",
    "    # your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test\n",
    "\"\"\"\n",
    "Expected Result\n",
    "--> \n",
    "{\n",
    "'duration': 169,\n",
    " 'genre': [u'Adventure', u'Drama', u'Sci-Fi'],\n",
    " 'rating': 8.6,\n",
    " 'rating_count': 856762,\n",
    " 'review_count': 2668,\n",
    " 'title': u'Interstellar',\n",
    " 'year': 2014\n",
    "}\n",
    "\"\"\"\n",
    "parsing_detail_page(test_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "If you have succeeded in following all the steps above correctly,\n",
    "\n",
    "you should now be capable of scrapping a descripted page of any movie you want.\n",
    "\n",
    "However this implementation is only possible when you have the precise id data of the movie\n",
    "\n",
    "(In this case, the data we want is contained in 'movie_id').\n",
    "\n",
    "In order to obtain a larger data, we will need to scrap the movie_id set from the movie list page.\n",
    "\n",
    "If you look at the list page carefully, you can observe that the movies are sorted in oder of its popularity.\n",
    "\n",
    "|Year | Page | Search URL |\n",
    "|----------|-------------|--------------------------|\n",
    "|2016|1 |http://www.imdb.com/search/title?title_type=featurerelease_date=2016|\n",
    "|2016|2 |http://www.imdb.com/search/title?title_type=featurerelease_date=2016&start=51|\n",
    "|2016|3 |http://www.imdb.com/search/title?title_type=featurerelease_date=2016&start=101|\n",
    "|2016|...|...|\n",
    "|2015|1|http://www.imdb.com/search/title?title_type=featurerelease_date=2015|\n",
    "|2015|2|http://www.imdb.com/search/title?title_type=featurerelease_date=2015&start=51|\n",
    "|2015|...|...|\n",
    "|2014|1|http://www.imdb.com/search/title?title_type=featurerelease_date=2014|\n",
    "| .... | ....| ... |\n",
    "\n",
    "Now you need to define a function that extracts a movie id set from the given movie search page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Function\n",
    "parsing_year_page\n",
    "\n",
    "Given a year, fetch serach result page and return the movie ids in that search page\n",
    "\n",
    "@Inputs\n",
    "---\n",
    "year: int\n",
    "    the year in which you want to search\n",
    "    \n",
    "page: int (optional, default=1)\n",
    "    the page of the search page in that year\n",
    "\n",
    "@Returns\n",
    "---\n",
    "movie_ids: array\n",
    "\"\"\"\n",
    "\n",
    "# each page has 50 movies sorted by popularity\n",
    "def get_movie_ids_in_year(year, page=1):    \n",
    "    # your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test\n",
    "\"\"\"\n",
    "Expected Result\n",
    "--> [u'tt1524930',\n",
    "     u'tt4178092',\n",
    "     u'tt1781922',\n",
    "     u'tt1655441',\n",
    "     u'tt2140379',\n",
    "     u'tt4270516', ....]\n",
    "\"\"\"\n",
    "get_movie_ids_in_year(2015, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------\n",
    "__Caution: This block code needs a lot of time to finish. Please just download dump data__\n",
    "\n",
    "Combining the functions you have implemented above, you can scrap the top 150 movies from 2000 to 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years = range(2000, 2016) # 2000 ~ 2015\n",
    "pages = [1,2,3]\n",
    "\n",
    "def get_data(years, pages=[1]):\n",
    "    movie_ids = [movie_id\n",
    "                 for year in years\n",
    "                 for page in pages\n",
    "                 for movie_id in get_movie_ids_in_year(year, page)]\n",
    "    \n",
    "    data = { movie_id : parsing_detail_page(get_movie_detaill_page(movie_id))\n",
    "            for movie_id in movie_ids}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = get_data(years, pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save crawling dump data\n",
    "import json\n",
    "data_str = json.dumps(data)\n",
    "f = open('data/imdb_cose471_sample.json', 'a')\n",
    "f.write(data_str)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "1. download [dump data](https://github.com/MinhwanYu/cose471_2016/blob/master/data/imdb_cose471_sample.json)\n",
    " ( top150 movies from 2000 to 2014)\n",
    "\n",
    "2. execute below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load dump crawling data\n",
    "f = open('data/imdb_cose471_sample.json')\n",
    "c = f.read()\n",
    "f.close()\n",
    "\n",
    "data = json.loads(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Explore: Aggregation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies = pd.DataFrame(data)\n",
    "movies = movies.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.1\n",
    "\n",
    "Group the data by the standard 'year'.\n",
    "\n",
    "After using '.describe()', you should see\n",
    "\n",
    "|        |              |duration | rating | rating_count | review_count | title |\n",
    "|-----------|-------------------|------------------|--------------|---------------------------|----------------------------|-----------|\n",
    "|__year__  | | | | | ||\n",
    "|__2000__| __count__ | 150 | 150.0 | 150 | 150|150|\n",
    "|| __unique__ | 61 | 47.0 | 150 | 130 |150|\n",
    "|| __top__ | 90 | 7.3 | 17151| 89 |The Adventures of Rocky &amp; Bullwinkle|\n",
    "|| __freq__ | 7 | 8.0 | 1 | 3 |1|\n",
    "|__2001__| __count__ | 150 | 150.0 | 150 | 150|150|\n",
    "|....|....|....|....|....|....|....|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year_group_movies = None\n",
    "#your code hear\n",
    "\n",
    "year_group_movies.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.2\n",
    "\n",
    "Calculate the minimum, maximum, average number of reviews by each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code hear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.3\n",
    "\n",
    "plot the graph\n",
    "> x-axis: year (2000-2015)\n",
    "> y-axis\n",
    ">> line1 : review max value\n",
    ">>\n",
    ">> line2 : review mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code hear"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
